"""
object_detector.py (ìˆ˜ì • ë²„ì „)
-------------------------------
YOLOv8 íƒì§€ + ë¶„ë¥˜ + ê±°ë¦¬ ê¸°ë°˜ ê·¼ì ‘ ì´ë²¤íŠ¸
"""

import time
import cv2
import numpy as np
from ultralytics import YOLO
import shared_state
import os

# ======================================
# ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì„¤ì •
# ======================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ - ì—¬ëŸ¬ ìœ„ì¹˜ í™•ì¸
def find_model_file(filename):
    """ëª¨ë¸ íŒŒì¼ì„ ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì°¾ê¸°"""
    possible_paths = [
        os.path.join(BASE_DIR, "models", filename),
        os.path.join(BASE_DIR, "..", filename),  # ìƒìœ„ ë””ë ‰í† ë¦¬
        os.path.join(BASE_DIR, filename),  # í˜„ì¬ ë””ë ‰í† ë¦¬
        os.path.join("/home/keonha/AI_CAR", filename),  # ì ˆëŒ€ ê²½ë¡œ
        os.path.join("/home/keonha/AI_CAR/test", filename),
    ]

    for path in possible_paths:
        if os.path.exists(path):
            print(f"  [âœ“] ëª¨ë¸ íŒŒì¼ ë°œê²¬: {path}")
            return path

    # best.pt íŒŒì¼ë„ ì‹œë„
    if "detector" in filename:
        for path in possible_paths:
            best_path = path.replace(filename, "best.pt")
            if os.path.exists(best_path):
                print(f"  [âœ“] ëŒ€ì²´ ëª¨ë¸ íŒŒì¼ ë°œê²¬: {best_path}")
                return best_path

    print(f"  [âš ï¸] ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
    return None

DETECTOR_PATH = find_model_file("sign_traffic_detector.pt")
CLASSIFIER_PATH = find_model_file("sign_traffic_classifier.pt")

MIN_AREA = 5000        # ë„ˆë¬´ ì‘ì€ ê°ì²´ ì œì™¸
NEAR_AREA = 20000      # ê·¼ì ‘ íŒë‹¨ ê¸°ì¤€
CONF_THRESHOLD = 0.7   # ì‹ ë¢°ë„ ì„ê³„ê°’
COOLDOWN = 3.0         # ê·¼ì ‘ ì´ë²¤íŠ¸ ì¿¨ë‹¤ìš´


def object_detect_loop():
    print("=" * 70)
    print(" YOLOv8 Object Detector (BGRâ†’RGB ë³€í™˜ ì ìš©)")
    print("=" * 70)

    # ëª¨ë¸ íŒŒì¼ í™•ì¸
    if not DETECTOR_PATH:
        print("  [âŒ] Detector ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("  [INFO] best.pt íŒŒì¼ì„ ë‹¤ìŒ ìœ„ì¹˜ ì¤‘ í•˜ë‚˜ì— ë°°ì¹˜í•˜ì„¸ìš”:")
        print("        - /home/keonha/AI_CAR/best.pt")
        print("        - /home/keonha/AI_CAR/test/best.pt")
        print("  [INFO] ê°ì²´ ì¸ì‹ ë¹„í™œì„±í™” - ë¼ì¸ íŠ¸ë ˆì´ì‹±ë§Œ ë™ì‘")
        while True:
            time.sleep(1)  # ìŠ¤ë ˆë“œ ìœ ì§€ (í¬ë˜ì‹œ ë°©ì§€)
        return

    # ClassifierëŠ” ì˜µì…˜
    use_classifier = CLASSIFIER_PATH is not None

    # ëª¨ë¸ ë¡œë“œ
    detector = YOLO(DETECTOR_PATH)
    classifier = YOLO(CLASSIFIER_PATH) if use_classifier else None

    print(f"  [âœ“] Detector ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    if use_classifier:
        print(f"  [âœ“] Classifier ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        print(f"  [âš ï¸] Classifier ëª¨ë¸ ì—†ìŒ - ê¸°ë³¸ ë¶„ë¥˜ë§Œ ì‚¬ìš©")

    last_action_time = 0
    last_label = None

    try:
        while True:
            # ===============================
            # 1ï¸ìµœì‹  í”„ë ˆì„ íšë“ (BGR)
            # ===============================
            with shared_state.lock:
                frame_bgr = getattr(shared_state, "latest_frame", None)

            if frame_bgr is None:
                time.sleep(0.05)
                continue

            # YOLO ì…ë ¥ìš© RGBë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)

            # ROI: ì˜¤ë¥¸ìª½ ì ˆë°˜ (640x480 ê¸°ì¤€ 320~640)
            height, width = frame_rgb.shape[:2]
            roi_rgb = frame_rgb[:, width // 2:]
            roi_bgr = frame_bgr[:, width // 2:]  # ë””ë²„ê¹…ìš© ì‹œê°í™”

            results = detector(roi_rgb, verbose=False)
            now = time.time()

            detected_label = None
            nearest_area = 0
            traffic_detected = False
            traffic_area = 0

            # ===============================
            #  íƒì§€ ê²°ê³¼ ì²˜ë¦¬
            # ===============================
            for box in results[0].boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                area = (x2 - x1) * (y2 - y1)
                conf = float(box.conf[0])
                cls_id = int(box.cls[0])
                cls_name = results[0].names[cls_id]

                if area < MIN_AREA or conf < CONF_THRESHOLD:
                    continue

                # Classifier ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë¶„ë¥˜
                if use_classifier and classifier:
                    # crop ì˜ì—­ ë¶„ë¥˜ (RGB ê¸°ì¤€)
                    crop_rgb = roi_rgb[y1:y2, x1:x2]
                    cls_res = classifier.predict(crop_rgb, imgsz=224, verbose=False)
                    sub_id = int(cls_res[0].probs.top1)
                    sub_name = cls_res[0].names[sub_id]
                    sub_conf = float(cls_res[0].probs.top1conf)

                    if sub_conf < 0.8:
                        continue
                else:
                    # Classifier ì—†ì´ ê¸°ë³¸ ë¼ë²¨ ì‚¬ìš©
                    sub_name = cls_name if 'cls_name' in locals() else "object"
                    sub_conf = conf

                # ì‹ í˜¸ë“± ì²˜ë¦¬
                if sub_name.startswith("traffic"):
                    traffic_detected = True
                    traffic_area = area
                    continue

                # ê°€ì¥ í° ë©´ì  ê°ì²´ ì„ íƒ
                if area > nearest_area:
                    nearest_area = area
                    detected_label = sub_name

                # ë””ë²„ê¹…ìš© í‘œì‹œ
                cv2.rectangle(roi_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(roi_bgr, f"{sub_name} ({conf:.2f})", (x1, y1 - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

            # ===============================
            # shared_state ê°±ì‹  ë° ë¡œê¹…
            # ===============================
            with shared_state.lock:
                # ê¸°ì¡´ ìƒíƒœ ë°±ì—… (ë³€ê²½ ê°ì§€ìš©)
                prev_detected = shared_state.object_detected
                prev_state = shared_state.object_state.copy()

                # ëª¨ë“  object_stateë¥¼ Falseë¡œ ì´ˆê¸°í™”
                for obj_name in shared_state.KNOWN_OBJECTS:
                    shared_state.object_state[obj_name] = False

                # ê°ì§€ëœ ê°ì²´ì˜ object_stateë¥¼ Trueë¡œ ì„¤ì •
                if detected_label:
                    if detected_label in shared_state.KNOWN_OBJECTS:
                        shared_state.object_state[detected_label] = True
                        shared_state.object_area[detected_label] = nearest_area
                        shared_state.object_last_seen[detected_label] = now

                # traffic ì‹ í˜¸ë“±ë„ ìƒíƒœ ì—…ë°ì´íŠ¸
                if traffic_detected:
                    shared_state.object_state["traffic"] = True
                    shared_state.object_area["traffic"] = traffic_area
                    shared_state.object_last_seen["traffic"] = now

                # ìƒˆë¡œìš´ ìƒíƒœ ì—…ë°ì´íŠ¸
                shared_state.object_detected = detected_label
                shared_state.object_distance = nearest_area

                # ìƒˆë¡œìš´ ê°ì²´ ê°ì§€ ì‹œ ë¡œê·¸
                if detected_label and detected_label != prev_detected:
                    timestamp = time.strftime("%H:%M:%S")
                    print(f"\n{'='*50}")
                    print(f"ğŸ¯ [ê°ì²´ ê°ì§€] {timestamp}")
                    print(f"  ğŸ“Œ ê°ì²´: {detected_label}")
                    print(f"  ğŸ“ í¬ê¸°: {nearest_area}")
                    print(f"  ğŸ­ ì‹ ë¢°ë„: {conf:.2%}")

                    # í‘œì§€íŒ ì¢…ë¥˜ë³„ ë©”ì‹œì§€
                    if detected_label in ["go_straight", "turn_left", "turn_right"]:
                        print(f"  ğŸ’¾ ë°©í–¥ í‘œì§€íŒ â†’ íì— ì €ì¥ë¨")
                    elif detected_label == "stop":
                        print(f"  ğŸ›‘ ì •ì§€ í‘œì§€íŒ â†’ ì¦‰ì‹œ ì •ì§€ ì˜ˆì •")
                    elif detected_label == "slow":
                        print(f"  âš ï¸ ì„œí–‰ í‘œì§€íŒ â†’ ì†ë„ ê°ì†Œ ì˜ˆì •")
                    print(f"{'='*50}\n")

                if traffic_detected:
                    shared_state.traffic_light_area = traffic_area
                    shared_state.traffic_light_last_ts = now
                    shared_state.right_turn_done = False

                    # ì‹ í˜¸ë“± ê°ì§€ ë¡œê·¸
                    if not prev_state.get("traffic", False):  # ìƒˆë¡œ ê°ì§€ëœ ê²½ìš°ë§Œ
                        timestamp = time.strftime("%H:%M:%S")
                        print(f"ğŸš¦ [ì‹ í˜¸ë“± ê°ì§€] {timestamp} | í¬ê¸°: {traffic_area}")

            # ===============================
            #  ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° ì²˜ë¦¬
            # ===============================
            if (
                detected_label
                and nearest_area > NEAR_AREA
                and (now - last_action_time > COOLDOWN)
            ):
                print(f"[DETECTED] {detected_label} (area={nearest_area})")
                with shared_state.lock:
                    shared_state.last_trigger = detected_label
                last_label = detected_label
                last_action_time = now

            # ===============================
            #  ë””ë²„ê·¸ ì¶œë ¥ (í”„ë ˆì„ë³„)
            # ===============================
            if detected_label:
                print(f" â†’ {detected_label:12s} | area={nearest_area:6.0f}")

            # VNC í™˜ê²½ì—ì„œ ë¯¸ë¦¬ë³´ê¸° ê°€ëŠ¥
            # cv2.imshow("YOLO Detection ROI (BGR view)", roi_bgr)
            # if cv2.waitKey(1) & 0xFF in (27, ord('q')):
            #     print("[INFO] Exit requested by user.")
            #     break

            time.sleep(0.2)

    except KeyboardInterrupt:
        print("\n[INFO] Object detector stopped by user.")
    finally:
        cv2.destroyAllWindows()
        print(" Detector cleanup complete")
